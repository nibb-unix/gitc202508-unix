{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DUEwJTg3vsaQ0om_UAfL5CgraIo1Z7_z","timestamp":1736147199187}],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyMY/AmXFXQAQpRrlaUfvzUz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **AlexNet with CIFAR-10**"],"metadata":{"id":"Iff-UVDySRZP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxCBlfM-bd3d"},"outputs":[],"source":["\"\"\"\n","1. 必要なコアライブラリのインポート\n","\n","torch: PyTorchのコアライブラリ。\n","torchvision: 画像処理用のデータセットやモデルを提供。\n","torch.nn: ニューラルネットワーク構築用のモジュール。\n","torch.optim: 最適化アルゴリズムを提供。\n","\"\"\"\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","\"\"\"\n","2. CIFAR-10データセットの読み込み\n","\n","CIFAR-10: 10クラスのカラー画像データセット（32x32ピクセル）。\n","\n","画像に前処理を行って汎化性能を向上させる（テスト画像はオリジナルのまま）。\n","tf.RandomHorizontalFlip(p=0.5)\n","50%の確率で画像を水平反転。\n","tf.RandomRotation(degrees=15)\n","画像を-15度から+15度の範囲でランダムに回転。\n","tf.RandomAffine(degrees=0, translate=(0.1, 0.1))\n","平行移動を加える。translate=(0.1, 0.1)は画像を幅と高さの±10%以内でランダムに平行移動。\n","tf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","画像のピクセル値を正規化（値を-1～1の範囲にスケーリング）。\n","transform=tf.ToTensor(): 画像データをTensor形式に変換。\n","\n","download=True: データセットがローカルにない場合に自動的にダウンロード。\n","\n","torchvision.transforms: データ前処理（変換）のユーティリティ。\n","\"\"\"\n","import torchvision.transforms as tf\n","\n","train_transform = tf.Compose([\n","    tf.RandomHorizontalFlip(p=0.5),\n","    tf.RandomRotation(degrees=15),\n","    tf.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","    tf.ToTensor(),\n","    tf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","test_transform = tf.Compose([\n","    tf.ToTensor(),\n","    tf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(\n","    root='./data/',\n","    train=True,\n","    transform=train_transform,\n","    download=True)\n","\n","test_dataset = torchvision.datasets.CIFAR10(\n","    root='./data/',\n","    train=False,\n","    transform=test_transform,\n","    download=True)\n","\n","\n","\"\"\"\n","3. データの大きさを確認\n","\n","データセットのサイズ（画像の数）と、1つのサンプル画像の形状（[チャンネル, 高さ, 幅]）を表示。\n","\"\"\"\n","print ('train_data = ', len(train_dataset))\n","print ('test_data = ', len(test_dataset))\n","image, label = train_dataset[0]\n","print (image.size())\n","\n","\n","\"\"\"\n","4. DataLoaderの設定\n","\n","DataLoader: データセットをミニバッチに分けて効率的にロード。\n","batch_size: ミニバッチのサイズ。\n","shuffle=True: トレーニングデータをランダムにシャッフル。\n","num_workers: データローディングに使用するスレッド数。\n","\"\"\"\n","train_loader = torch.utils.data.DataLoader(\n","      dataset=train_dataset,\n","      batch_size=64,\n","      shuffle=True,\n","      num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(\n","      dataset=test_dataset,\n","      batch_size=64,\n","      shuffle=False,\n","      num_workers=2)\n","\n","\n","\"\"\"\n","5. AlexNetモデルの定義\n","\n","特徴抽出部 (self.features):\n","\n","畳み込み層（Conv2d）とプーリング層（MaxPool2d）を組み合わせ、入力画像から特徴を抽出。\n","活性化関数としてReLUを使用。\n","畳み込みカーネルのサイズやパディングを変更し、AlexNetの簡略化バージョン。\n","分類部 (self.classifier):\n","\n","全結合層（Linear）で抽出した特徴を10クラスに分類。\n","ドロップアウトで過学習を防ぐ。\n","forwardメソッド:\n","\n","順伝播計算を定義。\n","特徴抽出後、4次元テンソルを平坦化して分類部に渡す。\n","\"\"\"\n","class AlexNet(nn.Module):\n","\n","    def __init__(self, num_classes):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256 * 4 * 4, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), 256 * 4 * 4)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","\"\"\"\n","6. デバイス設定とモデル構築\n","\n","cuda: GPUが利用可能な場合、GPUで計算を実行。\n","to(device): モデルを指定デバイスに移動。\n","\"\"\"\n","num_classes = 10\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","neuralnet = AlexNet(num_classes).to(device)\n","\n","\n","\"\"\"\n","7. 損失関数と最適化手法\n","\n","CrossEntropyLoss: クラス分類問題用の損失関数。\n","SGD: 確率的勾配降下法。学習率、モーメンタム、重み減衰（L2正則化）を設定。\n","\"\"\"\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(neuralnet.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","\n","\n","\"\"\"\n","8. トレーニングと評価\n","\n","trainモード:\n","モデルをトレーニングモードに設定し、順伝播→損失計算→逆伝播→パラメータ更新を実行。\n","ミニバッチごとに損失と正解率を計算。\n","\n","valモード:\n","モデルを評価モードに設定（勾配計算をオフ）。\n","テストデータセットを使用して損失と正解率を評価。\n","\n","平均値:\n","エポックごとの平均損失と平均正解率を計算して保存。\n","\"\"\"\n","num_epochs = 20\n","train_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n","\n","for epoch in range(num_epochs):\n","    train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0\n","\n","    # training mode\n","    neuralnet.train()\n","    for i, (images, labels) in enumerate(train_loader):\n","      images, labels = images.to(device), labels.to(device)\n","      optimizer.zero_grad()\n","      outputs = neuralnet(images)\n","      loss = criterion(outputs, labels)\n","      train_loss += loss.item()\n","      train_acc += (outputs.max(1)[1] == labels).sum().item()\n","      loss.backward()\n","      optimizer.step()\n","\n","    avg_train_loss = train_loss / len(train_loader.dataset)\n","    avg_train_acc = train_acc / len(train_loader.dataset)\n","\n","    # val mode\n","    neuralnet.eval()\n","    with torch.no_grad():\n","      for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = neuralnet(images)\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","        val_acc += (outputs.max(1)[1] == labels).sum().item()\n","    avg_val_loss = val_loss / len(test_loader.dataset)\n","    avg_val_acc = val_acc / len(test_loader.dataset)\n","\n","    print ('Epoch [{}/{}], Train_loss: {loss:.6f}, Validation_loss: {val_loss:.6f}'\n","                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss))\n","    train_loss_list.append(avg_train_loss)\n","    train_acc_list.append(avg_train_acc)\n","    val_loss_list.append(avg_val_loss)\n","    val_acc_list.append(avg_val_acc)\n","\n","\n","\"\"\"\n","9. 学習過程の可視化\n","\n","損失の可視化:\n","トレーニング損失と検証損失をエポックごとにプロット。\n","\n","正解率の可視化:\n","トレーニング正解率と検証正解率をエポックごとにプロット。\n","\n","matplotlib.pyplot: 可視化用ライブラリ。\n","\"\"\"\n","from matplotlib import pyplot as plt\n","\n","plt.figure()\n","plt.plot(range(num_epochs), train_loss_list, color='red', linestyle='-', linewidth=2, label='train_loss')\n","plt.plot(range(num_epochs), val_loss_list, color='green', linestyle='--', linewidth=2, label='validation_loss')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title('Loss')\n","plt.grid()\n","plt.xticks(range(num_epochs))\n","\n","plt.figure()\n","plt.plot(range(num_epochs), train_acc_list, color='red', linestyle='-', linewidth=2, label='train_accuracy')\n","plt.plot(range(num_epochs), val_acc_list, color='green', linestyle='--', linewidth=2, label='validation_accuracy')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.title('Accuracy')\n","plt.grid()\n","plt.xticks(range(num_epochs))"]},{"cell_type":"markdown","source":["# **学習済みモデルによるテスト画像へのラベリング**"],"metadata":{"id":"zQE5DbGESM5u"}},{"cell_type":"code","source":["\"\"\"\n","10. 学習済みモデルによるテスト画像へのラベリング\n","\n","np.random.choiceでランダムに10枚選択\n","\n","テストデータの中からランダムに10枚を選ぶ\n","torch.softmaxで確率計算\n","\n","出力（ロジット）を確率に変換する\n","probabilities.argmax(dim=1)で推定ラベル取得\n","\n","各画像について最も確率が高いクラスを推定ラベルとする\n","matplotlibで画像と結果をプロット\n","\n","選ばれた画像を表示し、推定ラベル、正解ラベル、推定確率をプロット\n","データの正規化を元に戻す\n","\n","画像を可視化するために(image * 0.5) + 0.5を行い、元のピクセル値（[0, 1]の範囲）に戻す\n","\n","各ラベル番号は以下のクラスを意味する。\n","(0)airplanes, (1)cars, (2)birds, (3)cats, (4)deer, (5)dogs, (6)frogs, (7)horses, (8)ships, and (9)trucks\n","\n","\"\"\"\n","\n","import numpy as np\n","\n","# ランダムに10枚の画像を選んで推定と表示を行う関数\n","def show_predictions(model, test_loader, num_samples=10):\n","    model.eval()  # モデルを評価モードに設定\n","    images, labels = next(iter(test_loader))  # テストデータから1バッチ分取得\n","    indices = np.random.choice(len(images), num_samples, replace=False)  # ランダムに画像を選択\n","    selected_images = images[indices]\n","    selected_labels = labels[indices]\n","\n","    with torch.no_grad():  # 推論時は勾配計算を無効化\n","        selected_images = selected_images.to(device)\n","        outputs = model(selected_images)\n","        probabilities = torch.softmax(outputs, dim=1)  # 各クラスの確率\n","        predicted_classes = probabilities.argmax(dim=1)  # 推定ラベル\n","\n","    # 画像と結果を表示\n","    plt.figure(figsize=(15, 5))\n","    for i in range(num_samples):\n","        plt.subplot(1, num_samples, i + 1)\n","        image = selected_images[i].cpu().numpy().transpose((1, 2, 0))  # 画像を[N, C, H, W]から[H, W, C]に変換\n","        image = (image * 0.5) + 0.5  # 正規化を元に戻す（[-1, 1] -> [0, 1]）\n","        plt.imshow(image)\n","        plt.title(f\"Label: {selected_labels[i].item()}\\nPred: {predicted_classes[i].item()}\\nProb: {probabilities[i][predicted_classes[i]].item():.2f}\")\n","        plt.axis('off')\n","    plt.show()\n","\n","# テスト画像で推定結果を表示\n","show_predictions(neuralnet, test_loader, num_samples=10)"],"metadata":{"id":"m8V5zNc8Izbp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **分類に貢献した特徴領域の可視化（Grad-CAM）**"],"metadata":{"id":"pu7F3iOzSHCA"}},{"cell_type":"code","source":["\"\"\"\n","11. 分類に貢献した特徴領域の可視化（Grad-CAM）\n","\n","このコードでは、GradCAMクラスを定義し、\n","モデルの特定の層の出力と勾配をフックしてGrad-CAMマップを生成する。\n","その後、生成されたマップを元画像に重ねて表示する。\n","target_layerは可視化したい層を指定（例ではfeatures[4]を使用）。\n","\n","# モデル内の層名表示は以下の通り実行する\n","for name, module in neuralnet.named_modules():\n","    print(name, \":\", module)\n","\"\"\"\n","\n","import torch.nn.functional as F\n","from torchvision.transforms.functional import normalize\n","import random\n","import cv2\n","\n","def denormalize(image):\n","    # [-1, 1] の範囲から [0, 1] の範囲に変換する関数\n","    return image * 0.5 + 0.5\n","\n","class GradCAM:\n","    def __init__(self, model, target_layer):\n","        # Grad-CAMクラスの初期化\n","        # model: PyTorchモデル\n","        # target_layer: 可視化したい層\n","        self.model = model\n","        self.target_layer = target_layer\n","        self.gradients = None  # 勾配を保存する変数\n","        self.activations = None  # アクティベーションを保存する変数\n","\n","        # フォワードパス時にアクティベーションを取得するフックを登録\n","        target_layer.register_forward_hook(self._forward_hook)\n","        # バックプロパゲーション時に勾配を取得するフックを登録\n","        target_layer.register_backward_hook(self._backward_hook)\n","\n","    def _forward_hook(self, module, input, output):\n","        # フォワードパス時に呼び出されるフック関数\n","        self.activations = output\n","\n","    def _backward_hook(self, module, grad_input, grad_output):\n","        # バックプロパゲーション時に呼び出されるフック関数\n","        self.gradients = grad_output[0]\n","\n","    def generate(self, input_image, class_idx):\n","        # Grad-CAMマップを生成する関数\n","        # input_image: 入力画像 (1枚)\n","        # class_idx: 対象のクラスインデックス (Noneの場合は自動で最大の出力クラスを選択)\n","\n","        self.model.eval()  # モデルを評価モードに設定\n","\n","        # フォワードパスを実行\n","        output = self.model(input_image)\n","        if class_idx is None:\n","            # クラスインデックスを出力の最大値から自動選択\n","            class_idx = output.argmax(dim=1).item()\n","\n","        # 出力の対象クラスに対してバックプロパゲーションを実行\n","        self.model.zero_grad()\n","        output[:, class_idx].backward()\n","\n","        # 勾配をチャンネルごとに平均化\n","        pooled_gradients = torch.mean(self.gradients, dim=(0, 2, 3))\n","        activations = self.activations[0]  # 対応するアクティベーションを取得\n","\n","        # アクティベーションに勾配の影響を掛け合わせる\n","        for i in range(len(pooled_gradients)):\n","            activations[i, :, :] *= pooled_gradients[i]\n","\n","        # チャンネル方向に平均化してヒートマップを生成\n","        heatmap = torch.mean(activations, dim=0).cpu().detach().numpy()\n","        heatmap = np.maximum(heatmap, 0)  # 負の値を0にクリップ\n","        heatmap /= np.max(heatmap)  # 正規化して [0, 1] の範囲に変換\n","        return heatmap\n","\n","def show_gradcam(model, gradcam, loader, device, num_samples=5):\n","    model.eval()\n","    all_images, all_labels = next(iter(loader))\n","    indices = random.sample(range(len(all_images)), num_samples)\n","    images, labels = all_images[indices].to(device), all_labels[indices]\n","\n","    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 15))\n","    for i in range(num_samples):\n","        image = images[i].unsqueeze(0)\n","        # GradCAM地図をつくる\n","        heatmap = gradcam.generate(image, class_idx=None)\n","\n","        # Predicted classを得る\n","        with torch.no_grad():\n","            pred = model(image).argmax(dim=1).item()\n","\n","        # heatmapをリサイズする\n","        heatmap = np.uint8(255 * heatmap)\n","        heatmap = cv2.resize(heatmap, (32, 32))\n","\n","        # 画像処理\n","        image_np = denormalize(images[i].cpu()).numpy().transpose(1, 2, 0)\n","\n","        # OpenCVのためにBGRへコンバート\n","        image_bgr = cv2.cvtColor(np.uint8(image_np * 255), cv2.COLOR_RGB2BGR)\n","\n","        # color mapを適用\n","        heatmap_img = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","        # Overlayをつくる\n","        overlay = cv2.addWeighted(\n","            image_bgr, 0.6,\n","            heatmap_img, 0.4,\n","            0\n","        )\n","\n","        # matplotlibのためにRGBにもどす\n","        overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","\n","        # original imageを表示\n","        axes[i, 0].imshow(image_np)\n","        axes[i, 0].axis('off')\n","        axes[i, 0].set_title(f\"Original (Label: {labels[i].item()}, Pred: {pred})\")\n","\n","        # GradCAMを表示\n","        axes[i, 1].imshow(overlay_rgb)\n","        axes[i, 1].axis('off')\n","        axes[i, 1].set_title(\"Grad-CAM\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Grad-CAMを初期化 (使用する層を指定)\n","target_layer = neuralnet.features[4]  # featuresの5番目の層を指定\n","gradcam = GradCAM(neuralnet, target_layer)\n","\n","# Grad-CAMを使用して可視化を実行\n","show_gradcam(neuralnet, gradcam, test_loader, device, num_samples=5)"],"metadata":{"id":"TzFJw38TcLQV"},"execution_count":null,"outputs":[]}]}